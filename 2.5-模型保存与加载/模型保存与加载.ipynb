{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras版本模型保存与加载\n",
    "\n",
    "## 保存模型与加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.randint(10, size=(1000, ))\n",
    "x_val = np.random.random((200, 32))\n",
    "y_val = np.random.randint(10, size=(200, ))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.randint(10, size=(200, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = tf.keras.Input(shape=(32,), name='digits')\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 2.3223 - sparse_categorical_accuracy: 0.1020 - val_loss: 2.3150 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 2.2962 - sparse_categorical_accuracy: 0.1300 - val_loss: 2.3136 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 2.2862 - sparse_categorical_accuracy: 0.1470 - val_loss: 2.3150 - val_sparse_categorical_accuracy: 0.0950\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 2.2744 - sparse_categorical_accuracy: 0.1460 - val_loss: 2.3179 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 2.2668 - sparse_categorical_accuracy: 0.1590 - val_loss: 2.3210 - val_sparse_categorical_accuracy: 0.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20974fa4ef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save_weights(\"adasd.h5\")\n",
    "\n",
    "model.load_weights(\"adasd.h5\")\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_model_tf_version\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "model.save('keras_model_tf_version', save_format='tf')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = tf.keras.models.load_model('keras_model_tf_version')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('keras_model_hdf5_version.h5')\n",
    "\n",
    "new_model = tf.keras.models.load_model('keras_model_hdf5_version.h5')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_saved_model_version\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'tf_saved_model_version')\n",
    "restored_saved_model = tf.saved_model.load('tf_saved_model_version')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: id=7078, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "         -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "        [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "         -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "        [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "         -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "        ...,\n",
       "        [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "         -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "        [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "         -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "        [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "          1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 13:44:40.779279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir tf_saved_model_version --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义版本模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # 定义自己需要的层\n",
    "        self.dense_1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(num_classes)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,32], tf.float32,name='digits')])\n",
    "    def call(self, inputs):\n",
    "        #定义前向传播\n",
    "        # 使用在 (in `__init__`)定义的层\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.random((1000, 10))\n",
    "x_val = np.random.random((200, 32))\n",
    "y_val = np.random.random((200, 10))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.random((200, 10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 优化器\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# 损失函数\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 准备metrics函数\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# 准备训练数据集\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# 准备测试数据集\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Training loss (for one batch) at step 0: 11.784499168395996\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10300000011920929\n",
      "Validation acc: 0.12999999523162842\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 12.349384307861328\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10300000011920929\n",
      "Validation acc: 0.12999999523162842\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 12.48736572265625\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10300000011920929\n",
      "Validation acc: 0.12999999523162842\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # 遍历数据集的batch_size\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # 更新训练集的metrics\n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "\n",
    "        # 每200 batches打印一次.\n",
    "        if step % 200 == 0:\n",
    "            print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n",
    "            print('Seen so far: %s samples' % ((step + 1) * 64))\n",
    "\n",
    "    # 在每个epoch结束时显示metrics。\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print('Training acc over epoch: %s' % (float(train_acc),))\n",
    "    # 在每个epoch结束时重置训练指标\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # 在每个epoch结束时运行一个验证集。\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val)\n",
    "        # 更新验证集merics\n",
    "        val_acc_metric(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print('Validation acc: %s' % (float(val_acc),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59265125,  0.12652864,  0.50779265, ...,  0.38236466,\n",
       "        -0.48236898, -0.29403484],\n",
       "       [ 0.3201392 ,  0.31926885,  0.5004305 , ...,  0.34327263,\n",
       "        -0.46210355, -0.29095772],\n",
       "       [ 0.17330498,  0.5561173 ,  0.46075135, ...,  0.31273955,\n",
       "        -0.14429614, -0.6220318 ],\n",
       "       ...,\n",
       "       [ 0.45052963,  0.07747109,  0.4848441 , ...,  0.1167865 ,\n",
       "        -0.53735   , -0.03418449],\n",
       "       [ 0.2759326 ,  0.5026181 ,  0.52613723, ...,  0.0728192 ,\n",
       "        -0.3806155 , -0.19111347],\n",
       "       [ 0.62080455,  1.1130711 ,  0.523637  , ...,  0.31726438,\n",
       "        -0.10991763, -0.76191264]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"adasd.h5\")\n",
    "model.load_weights(\"adasd.h5\")\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59265125,  0.12652864,  0.50779265, ...,  0.38236466,\n",
       "        -0.48236898, -0.29403484],\n",
       "       [ 0.3201392 ,  0.31926885,  0.5004305 , ...,  0.34327263,\n",
       "        -0.46210355, -0.29095772],\n",
       "       [ 0.17330498,  0.5561173 ,  0.46075135, ...,  0.31273955,\n",
       "        -0.14429614, -0.6220318 ],\n",
       "       ...,\n",
       "       [ 0.45052963,  0.07747109,  0.4848441 , ...,  0.1167865 ,\n",
       "        -0.53735   , -0.03418449],\n",
       "       [ 0.2759326 ,  0.5026181 ,  0.52613723, ...,  0.0728192 ,\n",
       "        -0.3806155 , -0.19111347],\n",
       "       [ 0.62080455,  1.1130711 ,  0.523637  , ...,  0.31726438,\n",
       "        -0.10991763, -0.76191264]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_saved_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = tf.keras.models.load_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('path_to_my_model',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('path_to_my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59265125,  0.12652864,  0.50779265, ...,  0.38236466,\n",
       "        -0.48236898, -0.29403484],\n",
       "       [ 0.3201392 ,  0.31926885,  0.5004305 , ...,  0.34327263,\n",
       "        -0.46210355, -0.29095772],\n",
       "       [ 0.17330498,  0.5561173 ,  0.46075135, ...,  0.31273955,\n",
       "        -0.14429614, -0.6220318 ],\n",
       "       ...,\n",
       "       [ 0.45052963,  0.07747109,  0.4848441 , ...,  0.1167865 ,\n",
       "        -0.53735   , -0.03418449],\n",
       "       [ 0.2759326 ,  0.5026181 ,  0.52613723, ...,  0.0728192 ,\n",
       "        -0.3806155 , -0.19111347],\n",
       "       [ 0.62080455,  1.1130711 ,  0.523637  , ...,  0.31726438,\n",
       "        -0.10991763, -0.76191264]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.MyModel object at 0x0000020981C30C18>, because its inputs are not defined.\n",
      "INFO:tensorflow:Assets written to: my_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'my_saved_model')\n",
    "restored_saved_model = tf.saved_model.load('my_saved_model')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: id=20472, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[0.36048555, 0.77584916, 0.5105363 , ..., 0.31300798, 0.15851551,\n",
       "         0.9504347 ],\n",
       "        [0.8945647 , 0.5531711 , 0.34847912, ..., 0.6248529 , 0.36228454,\n",
       "         1.1269959 ],\n",
       "        [0.12759946, 0.53442717, 0.7764567 , ..., 0.05553574, 0.31748763,\n",
       "         0.6228047 ],\n",
       "        ...,\n",
       "        [0.59310085, 0.6587581 , 0.19269958, ..., 0.47064906, 0.3493078 ,\n",
       "         0.650242  ],\n",
       "        [0.18195015, 0.9256924 , 0.9149718 , ..., 0.34724298, 0.24400793,\n",
       "         1.0152355 ],\n",
       "        [0.39257365, 0.8122336 , 1.0617772 , ..., 0.25777856, 0.25043324,\n",
       "         0.7244146 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 13:52:56.496039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir my_saved_model --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_test.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa  = list(map(lambda x: int(x),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(digits = tf.constant([aa]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
